{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a17571f5-fa0b-4a6c-af03-b3c0533258fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "import os\n",
    "#import logging\n",
    "os.environ[\"MODIN_ENGINE\"] = \"dask\"\n",
    "client = Client(silence_logs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "619b8a09-7ead-4a48-89e4-51e2d69bde3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acc5fbdb34149698bfa39cb45dbaa78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e451b3cc-063b-477e-adb4-e4e65c53320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 00:01:48.680930: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-20 00:01:48.685735: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-20 00:01:48.782579: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-20 00:01:48.784633: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 00:01:54.711935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-10-20 00:02:02.717417: I itex/core/devices/gpu/itex_gpu_runtime.cc:129] Selected platform: Intel(R) Level-Zero\n",
      "2023-10-20 00:02:02.718050: I itex/core/devices/gpu/itex_gpu_runtime.cc:154] number of sub-devices is zero, expose root device.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import intel_extension_for_tensorflow as itex\n",
    "import modin.pandas as pd\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, set_seed\n",
    "from datasets import Dataset\n",
    "from transformers import create_optimizer\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61f58734-c599-47e4-ab8f-3a7e56e70896",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "set_seed = SEED\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc20e1e8-37a5-4085-8ee3-ae7ece4c0e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/u132668/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5391aea-dde2-42ef-a3ef-43018e8d1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(BASE_DIR, 'data/train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "874ca4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(subset = ['span_text'], inplace=True)\n",
    "train.drop(train[train['Answer'] == 'unknown'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e7539c-b4bf-4849-8caa-f53fb7127b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Question'] = train['Question'].apply(lambda x: x.lower().strip())\n",
    "train['span_text'] = train['span_text'].apply(lambda x: x.lower().strip().strip(string.punctuation))\n",
    "train['Answer'] = train['Answer'].apply(lambda x: x.lower().strip().strip(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62656b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = train[(train['Answer'] == 'true') | (train['Answer'] == 'false')].copy()\n",
    "train_yn = train[(train['Answer'] == 'yes') | (train['Answer'] == 'no')].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10ed09-75bf-44a9-84c4-26b705fdf12f",
   "metadata": {},
   "source": [
    "# True/False Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0879a9f4-562e-4c5a-82b0-a53986aa889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = train_tf._to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8215ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf.rename(columns = {'Answer':'labels'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d947cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf['labels'].replace('false', 0, inplace=True)\n",
    "train_tf['labels'].replace('true', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af84ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label_tf = {0: \"false\", 1: \"true\"}\n",
    "label2id_tf = {\"false\": 0, \"true\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "033f6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb981bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 00:02:33.244413: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform XPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-20 00:02:33.244554: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:XPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: XPU, pci bus id: <undefined>)\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2, id2label=id2label_tf, label2id=label2id_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d6e4904",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ba5d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2, seed=SEED , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cb370af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = True\n",
    "max_length = 128\n",
    "def prepare_train_features(examples):\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"Question\" if pad_on_right else \"span_text\"],\n",
    "        examples[\"span_text\" if pad_on_right else \"Question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f9c36f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1815dd63f846c9a50ce377bf5b8c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151bcf8ccd8a42d194af3e3de128c328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = dataset.map(prepare_train_features, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "train_tokenized_data = tokenized_data['train'].add_column('labels', dataset['train']['labels'])\n",
    "test_tokenized_data = tokenized_data['test'].add_column('labels', dataset['test']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4e408fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_epochs = 3\n",
    "total_train_steps = (len(tokenized_data[\"train\"]) // batch_size) * num_epochs\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=1e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=total_train_steps,\n",
    "    #weight_decay_rate = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89f10c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = train_tokenized_data.to_tf_dataset(\n",
    "       columns=['input_ids', 'attention_mask', 'label'],\n",
    "       batch_size=batch_size\n",
    "    )\n",
    "tf_validation_set = test_tokenized_data.to_tf_dataset(\n",
    "       columns=['input_ids', 'attention_mask', 'label'],\n",
    "       batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11d3fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "344b6fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 00:03:21.790372: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - ETA: 0s - loss: 1.4394 - accuracy: 0.6364"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 00:03:45.169724: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 56s 322ms/step - loss: 1.4394 - accuracy: 0.6364 - val_loss: 2.2391 - val_accuracy: 0.4167\n",
      "Epoch 2/3\n",
      "44/44 [==============================] - 8s 181ms/step - loss: 0.7689 - accuracy: 0.7500 - val_loss: 1.7260 - val_accuracy: 0.4167\n",
      "Epoch 3/3\n",
      "44/44 [==============================] - 9s 197ms/step - loss: 0.5438 - accuracy: 0.7955 - val_loss: 1.7204 - val_accuracy: 0.4167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ff6e9bd330>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c71f14e3-9bab-48b1-9a2d-5081384f5e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/u132668/saved_models/BoolQA/TrueFalseQA/v2/tokenizer_config.json',\n",
       " '/home/u132668/saved_models/BoolQA/TrueFalseQA/v2/special_tokens_map.json',\n",
       " '/home/u132668/saved_models/BoolQA/TrueFalseQA/v2/vocab.txt',\n",
       " '/home/u132668/saved_models/BoolQA/TrueFalseQA/v2/added_tokens.json',\n",
       " '/home/u132668/saved_models/BoolQA/TrueFalseQA/v2/tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(os.path.join(BASE_DIR,'saved_models/BoolQA/TrueFalseQA/v2'))\n",
    "tokenizer.save_pretrained(os.path.join(BASE_DIR,'saved_models/BoolQA/TrueFalseQA/v2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81002d15-05d5-400e-8b4d-283da2f657fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ee12fc5c0b4e52a4535d7fab0f954f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/WaRKiD/distilbert-base-uncased-finetuned-intel-llm-tf-dataset/commit/76a94084d309f27fc6d51ff8de218b7cadb89f21', commit_message='Upload tokenizer', commit_description='', oid='76a94084d309f27fc6d51ff8de218b7cadb89f21', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"WaRKiD/distilbert-base-uncased-finetuned-intel-llm-tf-dataset\")\n",
    "tokenizer.push_to_hub(\"WaRKiD/distilbert-base-uncased-finetuned-intel-llm-tf-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f71b74-8d54-4e60-aa63-7a47486126a0",
   "metadata": {},
   "source": [
    "# Yes/No Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c805ead4-fb61-4e5d-b2ac-ec9c3e61c27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yn = train_yn._to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98a7cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yn.rename(columns = {'Answer':'labels'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c48cd2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yn['labels'].replace('no', 0, inplace=True)\n",
    "train_yn['labels'].replace('yes', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fe1fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label_yn = {0: \"no\", 1: \"yes\"}\n",
    "label2id_yn = {\"no\": 0, \"yes\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b8c7fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fd7f5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2, id2label=id2label_yn, label2id=label2id_yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c291150",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(train_yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ae0ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2, seed=SEED , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b73a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = True\n",
    "max_length = 128\n",
    "def prepare_train_features(examples):\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"Question\" if pad_on_right else \"span_text\"],\n",
    "        examples[\"span_text\" if pad_on_right else \"Question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a24e7253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ccc180cf0a4c8085f46d5b571402ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7858 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a52417363fc45ee9b4faef09c324f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = dataset.map(prepare_train_features, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "train_tokenized_data = tokenized_data['train'].add_column('labels', dataset['train']['labels'])\n",
    "test_tokenized_data = tokenized_data['test'].add_column('labels', dataset['test']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fb8350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_epochs = 3\n",
    "total_train_steps = (len(tokenized_data[\"train\"]) // batch_size) * num_epochs\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=1e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=total_train_steps,\n",
    "    #weight_decay_rate = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c9a6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = train_tokenized_data.to_tf_dataset(\n",
    "       columns=['input_ids', 'attention_mask', 'label'],\n",
    "       batch_size=batch_size\n",
    "    )\n",
    "tf_validation_set = test_tokenized_data.to_tf_dataset(\n",
    "       columns=['input_ids', 'attention_mask', 'label'],\n",
    "       batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "219e8495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8368a142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 00:11:31.377618: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983/983 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.6752"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 00:14:51.887587: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983/983 [==============================] - 250s 216ms/step - loss: 0.6333 - accuracy: 0.6752 - val_loss: 0.5191 - val_accuracy: 0.7486\n",
      "Epoch 2/3\n",
      "983/983 [==============================] - 203s 206ms/step - loss: 0.4562 - accuracy: 0.7870 - val_loss: 0.4849 - val_accuracy: 0.7898\n",
      "Epoch 3/3\n",
      "983/983 [==============================] - 206s 210ms/step - loss: 0.3401 - accuracy: 0.8595 - val_loss: 0.4899 - val_accuracy: 0.7858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1500751bb340>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3b53908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/u132668/saved_models/BoolQA/YesNoQA/v2/tokenizer_config.json',\n",
       " '/home/u132668/saved_models/BoolQA/YesNoQA/v2/special_tokens_map.json',\n",
       " '/home/u132668/saved_models/BoolQA/YesNoQA/v2/vocab.txt',\n",
       " '/home/u132668/saved_models/BoolQA/YesNoQA/v2/added_tokens.json',\n",
       " '/home/u132668/saved_models/BoolQA/YesNoQA/v2/tokenizer.json')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(os.path.join(BASE_DIR,'saved_models/BoolQA/YesNoQA/v2'))\n",
    "tokenizer.save_pretrained(os.path.join(BASE_DIR,'saved_models/BoolQA/YesNoQA/v2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a0e9486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0546562b3f93460b833bb6a7a83eb6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/WaRKiD/distilbert-base-uncased-finetuned-intel-llm-yn-dataset/commit/52869c40a1d4e72cc5b9e6b3d42857a588aa131b', commit_message='Upload tokenizer', commit_description='', oid='52869c40a1d4e72cc5b9e6b3d42857a588aa131b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"WaRKiD/distilbert-base-uncased-finetuned-intel-llm-yn-dataset\")\n",
    "tokenizer.push_to_hub(\"WaRKiD/distilbert-base-uncased-finetuned-intel-llm-yn-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643c3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
