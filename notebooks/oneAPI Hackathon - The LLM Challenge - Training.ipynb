{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbbef6cf-695a-4a84-a40d-a1f3daa48abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "import os\n",
    "#import logging\n",
    "os.environ[\"MODIN_ENGINE\"] = \"dask\"\n",
    "client = Client(silence_logs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3584eb-15a0-46c0-8e8f-134f5afc22b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20ff0792e69449d909eca21bb3a9eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c37e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 03:52:06.471130: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-20 03:52:06.689962: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-20 03:52:07.642824: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-20 03:52:07.646213: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 03:52:15.330206: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-10-20 03:52:29.484851: I itex/core/devices/gpu/itex_gpu_runtime.cc:129] Selected platform: Intel(R) Level-Zero\n",
      "2023-10-20 03:52:29.485502: I itex/core/devices/gpu/itex_gpu_runtime.cc:154] number of sub-devices is zero, expose root device.\n"
     ]
    }
   ],
   "source": [
    "import modin.pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import intel_extension_for_tensorflow as itex\n",
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering, TFAutoModelForSequenceClassification, set_seed\n",
    "from datasets import Dataset\n",
    "from transformers import create_optimizer\n",
    "import string\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3731fc-7435-44ff-b060-642f3017a9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XPU:0', device_type='XPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "633f1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "set_seed = SEED\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85d3ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/u132668/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ebd58ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(BASE_DIR, 'data/train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c9dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['span_start','span_end','span_text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f712edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_story(text):\n",
    "    #text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub('--', ' ', text)\n",
    "    text = re.sub('\\s{2,}', ' ', text)\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eeacd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Story'] = train['Story'].apply(preprocess_story)\n",
    "train['Question'] = train['Question'].apply(lambda x: x.lower().strip().strip(string.punctuation))\n",
    "train['Answer'] = train['Answer'].apply(lambda x: x.lower().strip().strip(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6518e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = train[(train['Answer'] == 'true') | (train['Answer'] == 'false')].copy()\n",
    "train_yn = train[(train['Answer'] == 'yes') | (train['Answer'] == 'no')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13cb0d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qa = train.drop(train_tf.index)\n",
    "train_qa = train_qa.drop(train_yn.index)\n",
    "train_qa = train_qa.drop(train[train['Answer'] == 'unknown'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfb093f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qa['answer_start'] = train_qa.apply(lambda row: row['Story'].rfind(row['Answer']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ef373bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_contained_ans = train_qa[train_qa['answer_start']>=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b1be3",
   "metadata": {},
   "source": [
    "# QA Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99207a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"bert-large-uncased-whole-word-masking-finetuned-squad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9b82f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 03:54:22.339356: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform XPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-20 03:54:22.339537: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:XPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: XPU, pci bus id: <undefined>)\n",
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8594b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(train_story_contained_ans._to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3bcd740",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2, seed=SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35190943",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = True\n",
    "max_length = 512\n",
    "doc_stride = 128\n",
    "\n",
    "def prepare_train_features(examples):\n",
    "\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"Question\" if pad_on_right else \"Story\"],\n",
    "        examples[\"Story\" if pad_on_right else \"Question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"Answer\"][sample_index]\n",
    "        \n",
    "        if examples[\"Answer\"][sample_index] == -1:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            start_char = examples[\"answer_start\"][sample_index]\n",
    "            end_char = start_char + len(answers)\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                while (token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char):\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fa26b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10acedd6473649819e4533a1cb479a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35279 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffc6b0c62174cda85e32431168ce544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8820 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = dataset.map(prepare_train_features, batched=True, remove_columns=dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b096f3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 35378\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 8843\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edad8f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_epochs = 2\n",
    "total_train_steps = (len(tokenized_data[\"train\"]) // batch_size) * num_epochs\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=3e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=total_train_steps,\n",
    "    #weight_decay_rate = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4973ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_data[\"train\"],\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "tf_validation_set = model.prepare_tf_dataset(\n",
    "    tokenized_data[\"test\"],\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11413ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_question_answering\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  334092288 \n",
      "                                                                 \n",
      " qa_outputs (Dense)          multiple                  2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 334,094,338\n",
      "Trainable params: 334,094,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "985c296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bca489c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fa129c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 04:09:15.519449: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4422/4422 [==============================] - ETA: 0s - loss: 2.4656 - end_logits_accuracy: 0.4710 - start_logits_accuracy: 0.4189"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 04:28:52.550322: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4422/4422 [==============================] - 1482s 325ms/step - loss: 2.4656 - end_logits_accuracy: 0.4710 - start_logits_accuracy: 0.4189 - val_loss: 2.2246 - val_end_logits_accuracy: 0.5103 - val_start_logits_accuracy: 0.4548\n",
      "Epoch 2/2\n",
      "4422/4422 [==============================] - 1400s 317ms/step - loss: 2.3381 - end_logits_accuracy: 0.4801 - start_logits_accuracy: 0.4324 - val_loss: 2.1970 - val_end_logits_accuracy: 0.5132 - val_start_logits_accuracy: 0.4554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14be756f9930>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fa43044-071f-41e3-8f8f-f30d3334b9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/u132668/saved_models/QA/v2/tokenizer_config.json',\n",
       " '/home/u132668/saved_models/QA/v2/special_tokens_map.json',\n",
       " '/home/u132668/saved_models/QA/v2/vocab.txt',\n",
       " '/home/u132668/saved_models/QA/v2/added_tokens.json',\n",
       " '/home/u132668/saved_models/QA/v2/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(os.path.join(BASE_DIR,'saved_models/QA/v2'))\n",
    "tokenizer.save_pretrained(os.path.join(BASE_DIR,'saved_models/QA/v2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d934cdf7-c785-459e-a376-7cb724b03efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3780b1cf488f449590b2b9f476767ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/WaRKiD/bert-large-uncased-whole-word-masking-finetuned-intel-oneapi-llm-dataset/commit/711cfa75c2a0507226fde202e9b17fcb72c0a242', commit_message='Upload tokenizer', commit_description='', oid='711cfa75c2a0507226fde202e9b17fcb72c0a242', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"WaRKiD/bert-large-uncased-whole-word-masking-finetuned-intel-oneapi-llm-dataset\")\n",
    "tokenizer.push_to_hub(\"WaRKiD/bert-large-uncased-whole-word-masking-finetuned-intel-oneapi-llm-dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
