{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbbef6cf-695a-4a84-a40d-a1f3daa48abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "import os\n",
    "#import logging\n",
    "os.environ[\"MODIN_ENGINE\"] = \"dask\"\n",
    "client = Client(silence_logs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3584eb-15a0-46c0-8e8f-134f5afc22b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20ff0792e69449d909eca21bb3a9eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c37e22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 03:52:06.471130: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-20 03:52:06.689962: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-20 03:52:07.642824: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-20 03:52:07.646213: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-20 03:52:15.330206: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-10-20 03:52:29.484851: I itex/core/devices/gpu/itex_gpu_runtime.cc:129] Selected platform: Intel(R) Level-Zero\n",
      "2023-10-20 03:52:29.485502: I itex/core/devices/gpu/itex_gpu_runtime.cc:154] number of sub-devices is zero, expose root device.\n"
     ]
    }
   ],
   "source": [
    "import modin.pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import intel_extension_for_tensorflow as itex\n",
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering, TFAutoModelForSequenceClassification, set_seed\n",
    "from datasets import Dataset\n",
    "from transformers import create_optimizer\n",
    "import string\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3731fc-7435-44ff-b060-642f3017a9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XPU:0', device_type='XPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "633f1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "set_seed = SEED\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e85d3ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '/home/u132668/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ebd58ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(BASE_DIR, 'data/train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c9dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['span_start','span_end','span_text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f712edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_story(text):\n",
    "    #text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub('--', ' ', text)\n",
    "    text = re.sub('\\s{2,}', ' ', text)\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eeacd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Story'] = train['Story'].apply(preprocess_story)\n",
    "train['Question'] = train['Question'].apply(lambda x: x.lower().strip().strip(string.punctuation))\n",
    "train['Answer'] = train['Answer'].apply(lambda x: x.lower().strip().strip(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6518e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = train[(train['Answer'] == 'true') | (train['Answer'] == 'false')].copy()\n",
    "train_yn = train[(train['Answer'] == 'yes') | (train['Answer'] == 'no')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13cb0d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qa = train.drop(train_tf.index)\n",
    "train_qa = train_qa.drop(train_yn.index)\n",
    "train_qa = train_qa.drop(train[train['Answer'] == 'unknown'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfb093f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qa['answer_start'] = train_qa.apply(lambda row: row['Story'].rfind(row['Answer']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ef373bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_contained_ans = train_qa[train_qa['answer_start']>=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b1be3",
   "metadata": {},
   "source": [
    "# QA Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99207a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"bert-large-uncased-whole-word-masking-finetuned-squad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9b82f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 03:54:22.339356: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform XPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-20 03:54:22.339537: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:XPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: XPU, pci bus id: <undefined>)\n",
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8594b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(train_story_contained_ans._to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3bcd740",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2, seed=SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35190943",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = True\n",
    "max_length = 512\n",
    "doc_stride = 128\n",
    "\n",
    "def prepare_train_features(examples):\n",
    "\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"Question\" if pad_on_right else \"Story\"],\n",
    "        examples[\"Story\" if pad_on_right else \"Question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"Answer\"][sample_index]\n",
    "        \n",
    "        if examples[\"Answer\"][sample_index] == -1:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            start_char = examples[\"answer_start\"][sample_index]\n",
    "            end_char = start_char + len(answers)\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                while (token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char):\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fa26b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10acedd6473649819e4533a1cb479a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35279 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffc6b0c62174cda85e32431168ce544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8820 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = dataset.map(prepare_train_features, batched=True, remove_columns=dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b096f3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 35378\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 8843\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edad8f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_epochs = 2\n",
    "total_train_steps = (len(tokenized_data[\"train\"]) // batch_size) * num_epochs\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=3e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=total_train_steps,\n",
    "    #weight_decay_rate = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4973ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = model.prepare_tf_dataset(\n",
    "    tokenized_data[\"train\"],\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "tf_validation_set = model.prepare_tf_dataset(\n",
    "    tokenized_data[\"test\"],\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11413ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_question_answering\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  334092288 \n",
      "                                                                 \n",
      " qa_outputs (Dense)          multiple                  2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 334,094,338\n",
      "Trainable params: 334,094,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "985c296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bca489c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fa129c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 04:09:15.519449: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4422/4422 [==============================] - ETA: 0s - loss: 2.4656 - end_logits_accuracy: 0.4710 - start_logits_accuracy: 0.4189"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 04:28:52.550322: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4422/4422 [==============================] - 1482s 325ms/step - loss: 2.4656 - end_logits_accuracy: 0.4710 - start_logits_accuracy: 0.4189 - val_loss: 2.2246 - val_end_logits_accuracy: 0.5103 - val_start_logits_accuracy: 0.4548\n",
      "Epoch 2/2\n",
      "4422/4422 [==============================] - 1400s 317ms/step - loss: 2.3381 - end_logits_accuracy: 0.4801 - start_logits_accuracy: 0.4324 - val_loss: 2.1970 - val_end_logits_accuracy: 0.5132 - val_start_logits_accuracy: 0.4554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14be756f9930>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fa43044-071f-41e3-8f8f-f30d3334b9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/u132668/saved_models/QA/v2/tokenizer_config.json',\n",
       " '/home/u132668/saved_models/QA/v2/special_tokens_map.json',\n",
       " '/home/u132668/saved_models/QA/v2/vocab.txt',\n",
       " '/home/u132668/saved_models/QA/v2/added_tokens.json',\n",
       " '/home/u132668/saved_models/QA/v2/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(os.path.join(BASE_DIR,'saved_models/QA/v2'))\n",
    "tokenizer.save_pretrained(os.path.join(BASE_DIR,'saved_models/QA/v2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d934cdf7-c785-459e-a376-7cb724b03efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3780b1cf488f449590b2b9f476767ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/WaRKiD/bert-large-uncased-whole-word-masking-finetuned-intel-oneapi-llm-dataset/commit/711cfa75c2a0507226fde202e9b17fcb72c0a242', commit_message='Upload tokenizer', commit_description='', oid='711cfa75c2a0507226fde202e9b17fcb72c0a242', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"WaRKiD/bert-large-uncased-whole-word-masking-finetuned-intel-oneapi-llm-dataset\")\n",
    "tokenizer.push_to_hub(\"WaRKiD/bert-large-uncased-whole-word-masking-finetuned-intel-oneapi-llm-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbebc714",
   "metadata": {},
   "source": [
    "# BoolQA Training:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dda5b38",
   "metadata": {},
   "source": [
    "### True/False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e17e8fdc-e55f-4fdc-a6d1-5bd2b79ea325",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = train_tf._to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57b75b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf.rename(columns = {'Answer':'labels'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12d4f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf['labels'].replace('false', 0, inplace=True)\n",
    "train_tf['labels'].replace('true', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61a30947",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label_tf = {0: \"false\", 1: \"true\"}\n",
    "label2id_tf = {\"false\": 0, \"true\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c51a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f8f800b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009a1e501e284d97814573c5ec25332c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b53515bdc14aac87219d38b4d8d7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112a71287c1b4f3a82582a592a136943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84284c6f32e84ad29e67dfd90407949b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 08:01:24.826032: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform XPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-10-18 08:01:24.826095: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:XPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: XPU, pci bus id: <undefined>)\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2, id2label=id2label_tf, label2id=label2id_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f77e4d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "507d5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2, seed=SEED , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13d20173",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = True\n",
    "max_length = 512\n",
    "def prepare_train_features(examples):\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"Question\" if pad_on_right else \"Story\"],\n",
    "        examples[\"Story\" if pad_on_right else \"Question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "debf9cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500ab8ea72684e39a4853a7e8d7092ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4ec2697b644a179eeefa1f13de1967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = dataset.map(prepare_train_features, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "train_tokenized_data = tokenized_data['train'].add_column('labels', dataset['train']['labels'])\n",
    "test_tokenized_data = tokenized_data['test'].add_column('labels', dataset['test']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85971429",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_epochs = 3\n",
    "total_train_steps = (len(tokenized_data[\"train\"]) // batch_size) * num_epochs\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=3e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=total_train_steps,\n",
    "    weight_decay_rate = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9aa84b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = train_tokenized_data.to_tf_dataset(\n",
    "       columns=['input_ids', 'attention_mask', 'label'],\n",
    "       batch_size=batch_size\n",
    "    )\n",
    "tf_validation_set = test_tokenized_data.to_tf_dataset(\n",
    "       columns=['input_ids', 'attention_mask', 'label'],\n",
    "       batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67b544f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f4204e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 08:02:15.059308: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/48 [============================>.] - ETA: 0s - loss: 1.3165 - accuracy: 0.5106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 08:02:21.004773: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 12s 84ms/step - loss: 1.3184 - accuracy: 0.5000 - val_loss: 0.6894 - val_accuracy: 0.6923\n",
      "Epoch 2/3\n",
      "48/48 [==============================] - 2s 46ms/step - loss: 0.5492 - accuracy: 0.7500 - val_loss: 0.7840 - val_accuracy: 0.4615\n",
      "Epoch 3/3\n",
      "48/48 [==============================] - 2s 48ms/step - loss: 0.4359 - accuracy: 0.8542 - val_loss: 0.7906 - val_accuracy: 0.5385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d302529e10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "331d44f0-87ff-4a17-aafa-76469f3874b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/u132668/saved_models/BoolQA/TrueFalseQA/tokenizer_config.json',\n",
       " '/home/u132668/saved_models/BoolQA/TrueFalseQA/special_tokens_map.json',\n",
       " '/home/u132668/saved_models/BoolQA/TrueFalseQA/vocab.txt',\n",
       " '/home/u132668/saved_models/BoolQA/TrueFalseQA/added_tokens.json',\n",
       " '/home/u132668/saved_models/BoolQA/TrueFalseQA/tokenizer.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(os.path.join(BASE_DIR,'saved_models/BoolQA/TrueFalseQA'))\n",
    "tokenizer.save_pretrained(os.path.join(BASE_DIR,'saved_models/BoolQA/TrueFalseQA'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa7067",
   "metadata": {},
   "source": [
    "### Yes/No:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "524fdc5f-afe9-416a-b745-352866dd944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yn = train_yn._to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d265901",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yn.rename(columns = {'Answer':'labels'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cce40739",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yn['labels'].replace('no', 0, inplace=True)\n",
    "train_yn['labels'].replace('yes', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5009cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label_yn = {0: \"no\", 1: \"yes\"}\n",
    "label2id_yn = {\"no\": 0, \"yes\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36740ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fed1c3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2, id2label=id2label_yn, label2id=label2id_yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "205dbe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(train_yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d399a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2, seed=SEED , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "219fff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = True\n",
    "max_length = 512\n",
    "def prepare_train_features(examples):\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"Question\" if pad_on_right else \"Story\"],\n",
    "        examples[\"Story\" if pad_on_right else \"Question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afb3920b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081051f5c3a240eb8ddac82b86535855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8968 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3959a91cbff4657b192ebe394fd8f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2242 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = dataset.map(prepare_train_features, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "train_tokenized_data = tokenized_data['train'].add_column('labels', dataset['train']['labels'])\n",
    "test_tokenized_data = tokenized_data['test'].add_column('labels', dataset['test']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31ef2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_epochs = 3\n",
    "total_train_steps = (len(tokenized_data[\"train\"]) // batch_size) * num_epochs\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=3e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=total_train_steps,\n",
    "    weight_decay_rate = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48f5ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_set = train_tokenized_data.to_tf_dataset(\n",
    "       columns=['input_ids', 'attention_mask', 'label'],\n",
    "       batch_size=batch_size\n",
    "    )\n",
    "tf_validation_set = test_tokenized_data.to_tf_dataset(\n",
    "       columns=['input_ids', 'attention_mask', 'label'],\n",
    "       batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14088313",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b1cdc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 08:05:02.126473: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8968/8968 [==============================] - ETA: 0s - loss: 0.6905 - accuracy: 0.5494"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-18 08:11:13.007894: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type XPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8968/8968 [==============================] - 406s 45ms/step - loss: 0.6905 - accuracy: 0.5494 - val_loss: 0.6830 - val_accuracy: 0.5727\n",
      "Epoch 2/3\n",
      "8968/8968 [==============================] - 400s 45ms/step - loss: 0.6855 - accuracy: 0.5587 - val_loss: 0.6801 - val_accuracy: 0.5727\n",
      "Epoch 3/3\n",
      "8968/8968 [==============================] - 400s 45ms/step - loss: 0.6798 - accuracy: 0.5498 - val_loss: 0.6870 - val_accuracy: 0.5727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d301dee950>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "774a3faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/u132668/saved_models/BoolQA/YesNoQA/tokenizer_config.json',\n",
       " '/home/u132668/saved_models/BoolQA/YesNoQA/special_tokens_map.json',\n",
       " '/home/u132668/saved_models/BoolQA/YesNoQA/vocab.txt',\n",
       " '/home/u132668/saved_models/BoolQA/YesNoQA/added_tokens.json',\n",
       " '/home/u132668/saved_models/BoolQA/YesNoQA/tokenizer.json')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(os.path.join(BASE_DIR,'saved_models/BoolQA/YesNoQA'))\n",
    "tokenizer.save_pretrained(os.path.join(BASE_DIR,'saved_models/BoolQA/YesNoQA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d1afb-b229-41f0-a0d9-c15760eb40a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
